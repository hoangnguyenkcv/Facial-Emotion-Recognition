{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import errno\n",
    "import scipy.misc\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from parameters import DATASET, NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import  BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13806964906678030413\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6735474197\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17918161769655793941\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 expressions\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "image_height = 48\n",
    "image_width = 48\n",
    "window_size = 24\n",
    "window_step = 6\n",
    "ONE_HOT_ENCODING = False\n",
    "SAVE_IMAGES = False\n",
    "GET_LANDMARKS = True\n",
    "GET_HOG_FEATURES = True\n",
    "GET_HOG_IMAGES = True\n",
    "GET_HOG_WINDOWS_FEATURES = True\n",
    "SELECTED_LABELS = []\n",
    "\n",
    "expressions = [0,1,2,3,4,5,6]\n",
    "for i in range(0,len(expressions)):\n",
    "    label = int(expressions[i])\n",
    "    if (label >=0 and label<=6 ):\n",
    "        SELECTED_LABELS.append(label)\n",
    "        \n",
    "if SELECTED_LABELS == []:\n",
    "    SELECTED_LABELS = [0,1,2,3,4,5,6]\n",
    "print( str(len(SELECTED_LABELS)) + \" expressions\")\n",
    "\n",
    "IMAGES_PER_LABEL = 10000\n",
    "OUTPUT_FOLDER_NAME = \"fer2013\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Load  Data ######################\n",
    "def load_data(validation=False, test=False):\n",
    "    \n",
    "    data_dict = dict()\n",
    "    validation_dict = dict()\n",
    "    test_dict = dict()\n",
    "\n",
    "    if DATASET.name == \"Fer2013\":\n",
    "\n",
    "        # load train set\n",
    "        data_dict['X'] = np.load(DATASET.train_folder + '/images.npy')\n",
    "        data_dict['X'] = data_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
    "        if NETWORK.use_landmarks:\n",
    "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
    "        if NETWORK.use_hog_and_landmarks:\n",
    "            data_dict['X2'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
    "            data_dict['X2'] = np.array([x.flatten() for x in data_dict['X2']])\n",
    "            data_dict['X2'] = np.concatenate((data_dict['X2'], np.load(DATASET.train_folder + '/hog_features.npy')), axis=1)\n",
    "        data_dict['Y'] = np.load(DATASET.train_folder + '/labels.npy')\n",
    "        if DATASET.trunc_trainset_to > 0:\n",
    "            data_dict['X'] = data_dict['X'][0:DATASET.trunc_trainset_to, :, :]\n",
    "            if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
    "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :]\n",
    "            elif NETWORK.use_landmarks:\n",
    "                data_dict['X2'] = data_dict['X2'][0:DATASET.trunc_trainset_to, :, :]\n",
    "            data_dict['Y'] = data_dict['Y'][0:DATASET.trunc_trainset_to, :]\n",
    "\n",
    "        if validation:\n",
    "            # load validation set\n",
    "            validation_dict['X'] = np.load(DATASET.validation_folder + '/images.npy')\n",
    "            validation_dict['X'] = validation_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
    "            if NETWORK.use_landmarks:\n",
    "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
    "            if NETWORK.use_hog_and_landmarks:\n",
    "                validation_dict['X2'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
    "                validation_dict['X2'] = np.array([x.flatten() for x in validation_dict['X2']])\n",
    "                validation_dict['X2'] = np.concatenate((validation_dict['X2'], np.load(DATASET.validation_folder + '/hog_features.npy')), axis=1)\n",
    "            validation_dict['Y'] = np.load(DATASET.validation_folder + '/labels.npy')\n",
    "            if DATASET.trunc_validationset_to > 0:\n",
    "                validation_dict['X'] = validation_dict['X'][0:DATASET.trunc_validationset_to, :, :]\n",
    "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
    "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :]\n",
    "                elif NETWORK.use_landmarks:\n",
    "                    validation_dict['X2'] = validation_dict['X2'][0:DATASET.trunc_validationset_to, :, :]\n",
    "                validation_dict['Y'] = validation_dict['Y'][0:DATASET.trunc_validationset_to, :]\n",
    "        \n",
    "        if test:\n",
    "            # load test set\n",
    "            test_dict['X'] = np.load(DATASET.test_folder + '/images.npy')\n",
    "            test_dict['X'] = test_dict['X'].reshape([-1, NETWORK.input_size, NETWORK.input_size, 1])\n",
    "            if NETWORK.use_landmarks:\n",
    "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
    "            if NETWORK.use_hog_and_landmarks:\n",
    "                test_dict['X2'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
    "                test_dict['X2'] = np.array([x.flatten() for x in test_dict['X2']])\n",
    "                test_dict['X2'] = np.concatenate((test_dict['X2'], np.load(DATASET.test_folder + '/hog_features.npy')), axis=1)\n",
    "            test_dict['Y'] = np.load(DATASET.test_folder + '/labels.npy')\n",
    "            if DATASET.trunc_testset_to > 0:\n",
    "                test_dict['X'] = test_dict['X'][0:DATASET.trunc_testset_to, :, :]\n",
    "                if NETWORK.use_landmarks and NETWORK.use_hog_and_landmarks:\n",
    "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :]\n",
    "                elif NETWORK.use_landmarks:\n",
    "                    test_dict['X2'] = test_dict['X2'][0:DATASET.trunc_testset_to, :, :]\n",
    "                test_dict['Y'] = test_dict['Y'][0:DATASET.trunc_testset_to, :]\n",
    "\n",
    "        if not validation and not test:\n",
    "            return data_dict\n",
    "        elif not test:\n",
    "            return data_dict, validation_dict\n",
    "        else: \n",
    "            return data_dict, validation_dict, test_dict\n",
    "    else:\n",
    "        print( \"Unknown dataset\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, validation, test = load_data(validation=True, test= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 7)\n",
      "[[1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(data['Y'].shape)\n",
    "print(data['Y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parameter :\n",
    "input_size = 48\n",
    "Landmasks_size = data['X2'].shape[1]\n",
    "batch_size = 8\n",
    "no_training = data['X'].shape[0]\n",
    "no_validation = validation['X'].shape[0]\n",
    "no_test = test['X'].shape[0]\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train =  np.load('fer2013\\\\train_label.npy')\n",
    "from sklearn.utils import class_weight\n",
    "train_class_weight = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv11 (Conv2D)                 (None, 48, 48, 64)   640         input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 48, 48, 64)   256         conv11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 23, 23, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv12 (Conv2D)                 (None, 23, 23, 128)  73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 23, 23, 128)  512         conv12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 11, 11, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv13 (Conv2D)                 (None, 11, 11, 256)  295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 11, 11, 256)  1024        conv13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool13 (MaxPooling2D)           (None, 5, 5, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten11 (Flatten)             (None, 6400)         0           pool13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fc11 (Dense)                    (None, 4096)         26218496    flatten11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           fc11[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc12 (Dense)                    (None, 1024)         4195328     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             (None, 2728)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           fc12[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc21 (Dense)                    (None, 1024)         2794496     input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1024)         4096        fc21[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc13 (Dense)                    (None, 128)          131200      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc22 (Dense)                    (None, 128)          131200      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         fc13[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         fc22[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            1799        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 33,853,191\n",
      "Trainable params: 33,847,687\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CNN_model(no_classes =7, input_size = 48,  Landmasks_size= Landmasks_size): \n",
    "    images_input = Input(shape = (input_size, input_size,1), name='input1')\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv11')(images_input)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x1)\n",
    "    x1 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv12')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D((3, 3), strides=(2, 2), name='pool2')(x1)\n",
    "    x1 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv13')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D((3, 3), strides=(2, 2), name='pool13')(x1)\n",
    "    x1 = Flatten(name='flatten11')(x1)\n",
    "    x1 = Dense(4096, activation='relu', name='fc11')(x1)\n",
    "    x1 = Dropout(0.2)(x1)  \n",
    "    x1 = Dense(1024, activation='relu',name='fc12')(x1)\n",
    "    x1 = Dropout(0.2)(x1)  \n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dense(128, activation='relu', name='fc13')(x1)\n",
    "    images_network = BatchNormalization()(x1)\n",
    "\n",
    "    ##### hog and landmask network\n",
    "    landmarks_input = Input(shape = (Landmasks_size,), name='input2')\n",
    "    x2 = Dense(1024, activation='relu', name='fc21')(landmarks_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dense(128, activation='relu', name='fc22')(x2)\n",
    "    landmarks_network = BatchNormalization()(x2)\n",
    "\n",
    "    ##### concat\n",
    "    network = keras.layers.concatenate([images_network, landmarks_network], axis=1)\n",
    "    output = Dense(no_classes, activation='softmax')(network)\n",
    "\n",
    "    model = Model(inputs=[images_input, landmarks_input], outputs=output,name='fussed_model')\n",
    "    return model\n",
    "\n",
    "model = CNN_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, decay= 10e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "### training  \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# Save check point\n",
    "filepath = \"fer2013.weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose =1, save_best_only = True, mode ='max')\n",
    "callbacks_list= [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    x= [data['X'], data['X2']],\n",
    "    y = data['Y'],\n",
    "    batch_size = batch_size,\n",
    "    epochs = n_epochs,     \n",
    "#     steps_per_epoch = int(no_training / batch_size), \n",
    "    validation_data = ([validation['X'], validation['X2']], validation['Y']), \n",
    "#     validation_steps = int(no_validation / batch_size),     \n",
    "    shuffle=False, \n",
    "    class_weight=train_class_weight,\n",
    "    callbacks = callbacks_list, \n",
    "    verbose =2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot history \n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','valid'], loc= 'upper left' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
